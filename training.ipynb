{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tup√£: Multihead Encoders to Multihead Attention decoder.\n",
    "Desc:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.optim import Adam, RMSprop\n",
    "from data.preprocessing import *\n",
    "from data.data_utils import *\n",
    "from models.macro_architectures import *\n",
    "from models.df_models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_hour = 5  #hour\n",
    "sequence_length_minute = 300 #minute\n",
    "pred_length = 4 #hours\n",
    "dict_values = ['dst_kyoto', 'kp_gfz']\n",
    "device = get_default_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data and creating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000025132DD9E10>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"c:\\Users\\Innotronics\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1436, in _shutdown_workers\n",
      "    if self._persistent_workers or self._workers_status[worker_id]:\n",
      "AttributeError: '_MultiProcessingDataLoaderIter' object has no attribute '_workers_status'\n",
      "c:\\Users\\Innotronics\\Desktop\\SMFGF-SpaceApps\\data\\preprocessing.py:158: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  mg1 = pd.concat(mg1_list)\n"
     ]
    }
   ],
   "source": [
    "#DATA PROCESSING\n",
    "start_time = '20210101'\n",
    "end_time = '20230802'\n",
    "scrap_date = interval_time(start_time, end_time)\n",
    "months = list(set([day[:6] for day in scrap_date]))\n",
    "import_Dst(months)\n",
    "l1_sample, l2_sample, dst, kp = automated_preprocessing(scrap_date, sep = True)\n",
    "l1_sample_hour = (l1_sample[0].resample('60min').mean(), l1_sample[1].resample('60min').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_kp_dataset = KpData(l1_sample_hour, kp, sequence_length_hour, pred_length, hour=True, sep = True)\n",
    "minute_kp_dataset = KpData(l1_sample, kp, sequence_length_minute, pred_length, hour=False, sep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(hour_kp_dataset))\n",
    "\n",
    "train_hour_kp, test_hour_kp = random_split(hour_kp_dataset , [len(hour_kp_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 256  #Change based on GPU capacity\n",
    "\n",
    "train_hour_kp_dl = DataLoader(train_hour_kp, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_hour_kp_dl = DeviceDataLoader(train_hour_kp_dl, device)\n",
    "test_hour_kp_dl = DataLoader(test_hour_kp, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_hour_kp_dl = DeviceDataLoader(test_hour_kp_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test:5% training: 95%\n",
    "\n",
    "test_size = round(0.05*len(minute_kp_dataset))\n",
    "\n",
    "train_minute_kp, test_minute_kp = random_split(minute_kp_dataset , [len(minute_kp_dataset) - test_size, test_size])\n",
    "\n",
    "batch_size = 32  #Change based on GPU capacity\n",
    "\n",
    "train_minute_kp_dl = DataLoader(train_minute_kp, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "train_minute_kp_dl = DeviceDataLoader(train_minute_kp_dl, device)\n",
    "test_minute_kp_dl = DataLoader(test_minute_kp, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_minute_kp_dl = DeviceDataLoader(test_minute_kp_dl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyperparameters\n",
    "epochs = 20\n",
    "max_lr = 1e-4\n",
    "weigth_decay = 1e-6\n",
    "grad_clip = 1e-3\n",
    "opt_func = Adam\n",
    "#opt_func = RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training\n",
    "**Architectures descriptions**\n",
    "\n",
    "EncoderMultiheadAttentionLSTM(input, hidden, num_heads, architectures)\n",
    "\n",
    "EncoderMultiheadAttentionLSTM(input, hidden, num_heads, architectures)\n",
    "\n",
    "MultiHeaded2MultiheadAttentionLSTM(encoder_fc, encoder_mg,num_heads: list, architecture, output_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hour based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_fc = EncoderMultiheadAttentionLSTM(9, 5, 3, (5,5))\n",
    "encoder_mg = EncoderMultiheadAttentionLSTM(11, 5, 11, (5,5))\n",
    "model  = MultiHead2SingleOUT(encoder_fc, encoder_mg,[3,11], (5,5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]:\n",
      "\tlast_lr: 0.00001\n",
      "\ttrain_loss: 1.0489\n",
      "\tval_loss: 1.0235\n"
     ]
    }
   ],
   "source": [
    "history_hour = []\n",
    "history_hour += model.fit(epochs, max_lr,train_hour_kp_dl, test_hour_kp_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_hour.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minute based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "encoder_fc = EncoderMultiheadAttentionLSTM(9, 5, 3, (5,5))\n",
    "encoder_mg = EncoderMultiheadAttentionLSTM(11, 5, 11, (5,5))\n",
    "model  = MultiHead2SingleOUT(encoder_fc, encoder_mg,[3,11], (5,5), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_minute = []\n",
    "history_minute += model.fit(epochs, max_lr,train_minute_kp_dl, test_minute_kp_dl, weigth_decay, grad_clip, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_minute.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
